---
title: "Homework 3: Large language model (LLM) prompting"
---

**Due 2025-04-14, 11:59pm**. *Instructions last updated 2025-04-07.*

## Learning objectives
After completing this assignment, students will be able to:

* Prompt LLMs programmatically with templates (parameterized)
* Demonstrate the difference between zero-shot, few-shot, and chain-of-thought prompting
* Engineer and test different prompts


## Overview
In this assignment, you will explore different prompting techniques for OpenAI LLMs. You will fill in a Jupyter notebook hosted on the Pitt CRCD to run your code. 

**To get started, click on the [class nbgitpuller link](https://jupyter.crc.pitt.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fmichaelmilleryoder%2Fcs1671_jupyterhub&urlpath=lab%2Ftree%2Fcs1671_jupyterhub%2F&branch=main) and edit the template notebook, `hw3_template.ipynb`.**
You can run it on the standard CPU server; no GPU is needed.

## OpenAI account
The class OpenAI account is available for use in this assignment. Please see Canvas for an announcement with the API key you can use for the class account.

## Deliverables

1. Your code: the Jupyter notebook you modified from the template. Submit:
	*  your .ipynb file 
	* a **.html export of your notebook**. To get a .html version, click File > Save and Export Notebook As... > HTML from within JupyterLab.
2. A PDF report with answers to questions provided in the template notebook. Please name your report `hw3_{your pitt email id}.pdf`. No need to include @pitt.edu, just use the email ID before that part. For example: `report_mmyoder_hw3.pdf`. Make sure to include the following additional information:
	* any additional resources, references, or web pages you've consulted
	* any person with whom you've discussed the assignment and describe the nature of your discussions
	* any generative AI tool used, and how it was used
	* any unresolved issues or problems

Please submit all of this material on Canvas. We will grade your report and may look over your code.

## Background readings
The following optional readings are good references for LLM prompting:

*   [Language Models are Few-Shot Learners](https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fpdf%2F2005.14165.pdf). Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, ...others. ArXiV 2020.
*    [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fpdf%2F2107.13586.pdf). Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig. ACM Computing Surveys 2021.
*    [Best practices for prompt engineering with OpenAI API](https://www.google.com/url?q=https%3A%2F%2Fhelp.openai.com%2Fen%2Farticles%2F6654000-best-practices-for-prompt-engineering-with-openai-api). Jessica Shieh. OpenAI 2023.
*    [Training language models to follow instructions with human feedback](https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fpdf%2F2203.02155.pdf). Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, ...others. ArXiV 2020.
*    [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fpdf%2F2201.11903.pdf). Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, Denny Zhou. NeurIPS 2022.


<!--
## Grading
See rubric on Canvas.
-->

## Acknowledgments
This assignment is based on a homework assignment designed by Mark Yatskar and provided by Lorraine Li.
