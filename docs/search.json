[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Last revised 2025-04-21.\nA major component of this course is a hands-on final project. In this project, students will demonstrate an ability to build and evaluate an NLP system that takes in language data and automatically produces some sort of output.\nProjects will be done in groups of 2-4 students. Groups will be assigned by teaching staff based on interests, skills, and group preferences from students."
  },
  {
    "objectID": "project.html#project-idea-submission-form",
    "href": "project.html#project-idea-submission-form",
    "title": "Project",
    "section": "Project idea submission form",
    "text": "Project idea submission form\nDue 01-30.\nWith this form, you can fill out project ideas you might be interested in working on. You can fill out ideas from the example projects listed below or one of your own ideas. For your own ideas, consider what computer system you’d like to build that processes language in some form, interesting text datasets you’d like to work on, really anything! It is best if your idea has a dataset in mind, but this is not required.\nYou can fill out as many ideas as you’d like with this form. Ideas do not have to be fully sketched out. Submitting an idea does mean you will necessarily work on it. These ideas will be presented to all students anonymously. Each student must submit at least one idea for credit on this assignment, even if it’s just chosen from the example projects.\n\nExample projects\nMany of these projects are drawn from “shared tasks” where NLP researchers compete for the best performance on certain datasets. The instructor will provide data for these projects, though it may still require further preprocessing for use.\n\n1. Text classification\n\nGiven a short essay in response to a troubling news article, predict the level of empathy. See WASSA 2024 shared task Track 3.\nPredict emotion labels from tweets across many languages. See WASSA 2024 shared task\nGiven a news article and a list of “entities” (people, organizations, etc), predict roles such as protagonist, antagonist, and innocent. See SemEval 2025 Task 10, Subtask 1 on entity framing\nPredict news genre or media “frames” such as morality, economic, or crime and punishment from news articles in multiple languages. See SemEval 2023 Task 3, Subtasks 1 or 2\nPredict whether text was written by humans or generated by AI. Tasks include predicting for data across languages and for academic essays. See GenAI Content Detection Workshop, Task 1 or 2\nClassify tweets as sexist or not, or predict the “intent” of sexist tweets as direct, reported or judgemental. See EXIST 2024 Task 1 or Task 2\nPredict if similar words are redundant or not with the Semantic Pleonasm corpus developed right here at Pitt.\nPredict whether bills will pass in US state legislatures (Minnesota, Pennsylvania, or Virginia) based solely on the text, or in combination with other metadata such as the party sponsoring the bill.\n\n\n\n2. Machine translation\n\nTranslate customer service chats in between languages. See the WMT 2024 Chat Shared Task\nTranslate code-mixed Hinglish to English. See the WMT 2022 Code-mixed Machine Translation Task\nCreate a system to automatically correct (post-edit) machine translations. See the WMT 2022 Automatic Post-Editing Shared Task\n\n\n\n3. Information retrieval and extraction\n\nGiven a query, retrieve the most relevant passages from regulatory documents: https://www.codabench.org/competitions/3527/\nExtract important entities from scientific articles with the SCIRex dataset\n\n\n\n4. Question answering\n\nTrain a system to predict abstract terms related to a passage and answer multiple choice questions. See SemEval 2021 Task 4."
  },
  {
    "objectID": "project.html#project-group-match-day",
    "href": "project.html#project-group-match-day",
    "title": "Project",
    "section": "Project group match day",
    "text": "Project group match day\nIn class 02-05.\nStudents will form groups of 2-4 people around the following list of potential projects. Note that this list of project ideas is much greater than the final number of groups will be, so not all project ideas will have groups.\nProject idea list\n\nPredict whether text was written by humans or generated by AI. Tasks include predicting for data across languages and for academic essays. See GenAI Content Detection Workshop, Task 1 or 2 and dataset. This project is the same as project 1.5 in the example projects list above.\nTrain a system to predict abstract terms related to a passage and answer multiple choice questions. See SemEval 2021 Task 4 and dataset. This project is the same as project 4.1 in the example projects list above.\nClassify adversarial prompts for LLMs based on attack type, using publicly available red-teaming datasets.\nBuild an information retrieval system that finds relevant legal precedents for new cases.\nGiven a review of a restaurant, determine what type of restaurant it is from this Yelp dataset\nDetermine if a YouTube comment is like-farming/baiting. Examples include, “Only people from TikTok are allowed to like this comment,” “For every like this gets I’ll do a pushup,” “Like if you’re a true fan” etc). This can be important since spam accounts tend to copy and paste legitimate messages with problematic usernames or profile pictures.\nCompare hate speech by groups outside of the US with hateful language used by US groups. This project would use NLP techniques to analyze narrative, topic and style differences.\nAnalyze how women’s commentary online on computer science topics (for instance on Stack Overflow or YouTube) are received by other users. This could involve sentiment analysis.\nClassify tweet replies as bots or not.\nPredict bullish/bearish sentiment toward companies from sites like r/WSB or Yahoo Finance.\nDevelop language technologies for endangered languages and less-commonly spoken languages. This could involve building language models or machine translation systems for Ligurian, or automatically labeling syntax in Yupik or other languages\nPredict if a given text is a “dad joke” using this dataset.\nCompare sentiment toward bikes and bicyclists across biking-oriented and non-biking-oriented subreddits, with a focus on Pittsburgh.\nBuild a system to automatically simplify complex articles or papers into simple, easily digestible versions."
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Project",
    "section": "Project proposal",
    "text": "Project proposal\nDue 02-28.\nPlease submit one per group on Canvas. There is no required length or format for this report. This proposal will be a report with answers to a series of questions. It will include a peer review where you will rate your own performance and the performance of other group members through the form here.\n\nWhat is the problem or task you are focusing on?\nWhat is the format of the input and output of this task? For example, each input could be a sentence of text and the output could be a label from a discrete set of possible labels. Provide at least one example of input and output from your data.\nWhat data are you using? Please explain where these datasets are from and how they were constructed. Provide links to any URLs if the data is hosted online or links to papers if the dataset is published somewhere. If the data has labels or “gold” text that you are predicting or generating, where do those labels come from?\nWhat approach are you taking to building a NLP system to handle this task? What software packages are you planning to use to build this system? Except in some cases, the approach should draw on statistical approaches we’ve covered in class so far, such as n-gram representations of text. Talk to the instructor if you are not sure about this.\nHow are you evaluating your approach? What performance metrics are you going to use?\nWhat kinds of ethical issues may be raised by your model or data?\nWhat are the proposed steps needed for completion of (your proposed part) of the project? This should be in some detail, for example, loading and potentially cleaning the data, training models, trying different parameters, evaluating models, etc.\nWhat are roles and tasks of each person in the group? Though group members will contribute in various capacities, it is best if each person is responsible for at least one aspect of the project."
  },
  {
    "objectID": "project.html#project-proposal-presentation",
    "href": "project.html#project-proposal-presentation",
    "title": "Project",
    "section": "Project proposal presentation",
    "text": "Project proposal presentation\nIn class 03-10.\nGroups will make a brief presentation to the class outlining their proposed project, with Q&A and opportunities for feedback from other students. Please plan for maximum 5-minute presentations not including Q&A, which will be held right afterward for each group. Please add your slides to this shared PowerPoint presentation. Presentations are not graded. Cover at least these key points:\n\nProject motivation\nWhat data you are planning to use\nWhat approach/methods you plan to take\nHow you will evaluate your approach"
  },
  {
    "objectID": "project.html#progress-report",
    "href": "project.html#progress-report",
    "title": "Project",
    "section": "Progress report",
    "text": "Progress report\nDue 03-27.\nThe progress report will contain a substantive update on your group’s progress using traditional (usually n-gram based) approaches on your task, as well as a description of how you will use LLMs for your task. You do not have to repeat information from the project proposal except for basic descriptions of the project and Part 1 information if you already provided it in the proposal. Here are the details:\n\nPart 1: Data basic statistics and exploratory analysis\nIn this part, please provide the following information about your dataset. It’s fine to be working with multiple datasets; just complete this for each one or for a final dataset you will be using if you are combining datasets.\n\nThe number of rows (datapoints) in the dataset and what each datapoint corresponds to. If you are splitting the dataset into a training, test, and possible dev sets, how many rows are in each?\nThe number of columns in the dataset you will be using and what each corresponds to.\nIf applicable, the distribution of the target labels you are predicting. So for a binary sentiment classification task, how many rows in each set (except the test set) are marked negative or positive sentiment? This can be in a table or graph format.\nOptionally, any other distribution or data visualization that you think is helpful for understanding your dataset or task.\n\n\n\nPart 2: A result from baseline (traditional) approach\nIn your proposal, you described an initial baseline approach to your task, which for most groups was using n-gram features in some way. Please provide one (hopefully quantitative) result from your work so far in this direction. Ideally this would be a performance metric result from your baseline approach on a dev or test set. But if you’re not that far yet, you can also provide an example of working input and output from your system or part of a system, some sort of plot or other output. You can be up front about challenges you are facing for which you might need help; to get a good grade, I’ll just be looking for some sort of output from a working system or part of a system. If you are confused what this means for your project, contact the instructor.\n\n\nPart 3: LLM proposal\nIn the project, you will be comparing your baseline system’s performance to that of an LLM. Please describe how you might use an LLM programmatically to attempt your task. The simplest way to do this would be in a “zero-shot” setting where you simply ask the LLM to do the task, but even that requires setting up and passing your data to the LLM and evaluating it. Please describe what you plan to do and which LLM you plan on using. You can also propose using more advanced approaches such as in-context learning (few-shot prompting), chain-of-thought prompting, prompt optimization or fine-tuning. Not all groups have to use an LLM here if you have already talked to the instructor; in that case, please describe the rest of the approach you will be taking to complete the project.\n\n\nPart 4: Open questions and challenges\nPlease describe any open questions or challenges your group has at this point. Will you need any resources other than the ones provided in class (OpenAI API access, CRCD access) or have any other questions? Also describe if the roles for each of your team members have changed since the proposal and if so, what the new roles are.\n\n\nDeliverable\nAssemble your results and writing for each part in a document to submit as a PDF on Canvas. There is no required format for this document other than being in PDF format."
  },
  {
    "objectID": "project.html#final-report",
    "href": "project.html#final-report",
    "title": "Project",
    "section": "Final report",
    "text": "Final report\nDue 04-28.\nAt the end of the course, groups will provide a written report of their project. This project includes a quantitative comparison between at least two NLP systems on a clearly specified task or tasks. One of these is generally a more traditional NLP approach and the other involves LLMs, though your group’s project may vary if you have discussed this with the instructor.\nThis report will be in the ACL format found here. Feel free to use the Word or LaTeX templates (which is also available as an Overleaf template). The report should be a maximum of 8 pages, not including limitations, ethics, group member task breakdown, references sections or appendices. Feel free to include content from the project proposal and progress report. There is flexibility in section names, but please provide information about the following aspects of the project:\n\nAbstract: a brief overview of your entire project, including what approaches you took on which datasets and any findings.\nIntroduction: should include motivation for the project and more detail on the approaches you take and your final results.\nData\nMethods. Please clearly specify which techniques are novel/your own versus methods directly or indirectly from prior work (which is also fine).\nResults\nDiscussion: Please discuss the significance of the results that you see and any other comments about what these results indicate to you.\nFuture work. This is a good place to describe things you thought about but never had time to complete!\nLimitations (doesn’t count toward page limit)\nEthical issues (doesn’t count toward page limit)\nGroup member task breakdown (doesn’t count toward page limit). This section details the high-level tasks that each group member completed.\nReferences (doesn’t count toward page limit). If you are able to, please fill in full references instead of just URLs. The references can use any format.\nAppendices (optional, doesn’t count toward page limit). Additional figures or explanation in one or more appendices is allowed, but they will not necessarily be considered in grading.\n\nHere is the rubric that will be used in grading:\n\n\n\n\n\n\n\nRubric category\nPoints\n\n\n\n\nClear motivation for the work is provided\n4\n\n\nTask definition and format of the input and output is clear\n9\n\n\nApplicable dataset/s are chosen and preprocessed\n10\n\n\nBaseline system is properly designed and implemented\n15\n\n\nLLM-based system is properly designed and implemented\n15\n\n\nResults from a comparison between systems are provided\n20\n\n\nDiscussion is provided of the results and implications\n10\n\n\nPotential future work is discussed\n4\n\n\nLimitations of your approach or dataset are sufficiently discussed\n4\n\n\nEthical issues that may be raised by your system or dataset are sufficiently discussed\n4\n\n\nGroup member task breakdown is provided\n4\n\n\nProject content total\n95\n\n\nMeets all formatting requirements. Is maximum 8 pages, not including limitations, ethics, references or group member task breakdown\n7\n\n\nWriting is clear\n8\n\n\nWriting total\n15\n\n\nGroup member had a sufficient amount of workload in the project\n15\n\n\nTask and roles assigned to this group member were completed sufficiently\n15\n\n\nIndividual contribution total\n30\n\n\nGrand total\n140"
  },
  {
    "objectID": "project.html#final-presentation",
    "href": "project.html#final-presentation",
    "title": "Project",
    "section": "Final presentation",
    "text": "Final presentation\nIn class 04-30, 12-1:50p.\nGroups will present their finished work to the group, with Q&A and feedback opportunities from students. Please prepare a maximum 8-minute presentation. Add your slides to this shared PowerPoint presentation. Cover at least these key points:\n\nProject motivation (briefly)\nTask description, including example input and output\nData\nMethods, including your baseline system and your contemporary LLM-based approach (or whatever approaches you took)\nResults or findings from your baseline system and your contemporary LLM-based approach"
  },
  {
    "objectID": "hw3.html",
    "href": "hw3.html",
    "title": "Homework 3: Large language model (LLM) prompting",
    "section": "",
    "text": "Due 2025-04-14, 11:59pm. Instructions last updated 2025-04-07."
  },
  {
    "objectID": "hw3.html#learning-objectives",
    "href": "hw3.html#learning-objectives",
    "title": "Homework 3: Large language model (LLM) prompting",
    "section": "Learning objectives",
    "text": "Learning objectives\nAfter completing this assignment, students will be able to:\n\nPrompt LLMs programmatically with templates (parameterized)\nDemonstrate the difference between zero-shot, few-shot, and chain-of-thought prompting\nEngineer and test different prompts"
  },
  {
    "objectID": "hw3.html#overview",
    "href": "hw3.html#overview",
    "title": "Homework 3: Large language model (LLM) prompting",
    "section": "Overview",
    "text": "Overview\nIn this assignment, you will explore different prompting techniques for OpenAI LLMs. You will fill in a Jupyter notebook hosted on the Pitt CRCD to run your code.\nTo get started, click on the class nbgitpuller link and edit the template notebook, hw3_template.ipynb. You can run it on the standard CPU server; no GPU is needed."
  },
  {
    "objectID": "hw3.html#openai-account",
    "href": "hw3.html#openai-account",
    "title": "Homework 3: Large language model (LLM) prompting",
    "section": "OpenAI account",
    "text": "OpenAI account\nThe class OpenAI account is available for use in this assignment. Please see Canvas for an announcement with the API key you can use for the class account."
  },
  {
    "objectID": "hw3.html#deliverables",
    "href": "hw3.html#deliverables",
    "title": "Homework 3: Large language model (LLM) prompting",
    "section": "Deliverables",
    "text": "Deliverables\n\nYour code: the Jupyter notebook you modified from the template. Submit:\n\nyour .ipynb file\na .html export of your notebook. To get a .html version, click File &gt; Save and Export Notebook As… &gt; HTML from within JupyterLab.\n\nA PDF report with answers to questions provided in the template notebook. Please name your report hw3_{your pitt email id}.pdf. No need to include @pitt.edu, just use the email ID before that part. For example: report_mmyoder_hw3.pdf. Make sure to include the following additional information:\n\nany additional resources, references, or web pages you’ve consulted\nany person with whom you’ve discussed the assignment and describe the nature of your discussions\nany generative AI tool used, and how it was used\nany unresolved issues or problems\n\n\nPlease submit all of this material on Canvas. We will grade your report and may look over your code."
  },
  {
    "objectID": "hw3.html#background-readings",
    "href": "hw3.html#background-readings",
    "title": "Homework 3: Large language model (LLM) prompting",
    "section": "Background readings",
    "text": "Background readings\nThe following optional readings are good references for LLM prompting:\n\nLanguage Models are Few-Shot Learners. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, …others. ArXiV 2020.\nPre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig. ACM Computing Surveys 2021.\nBest practices for prompt engineering with OpenAI API. Jessica Shieh. OpenAI 2023.\nTraining language models to follow instructions with human feedback. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, …others. ArXiV 2020.\nChain-of-Thought Prompting Elicits Reasoning in Large Language Models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, Denny Zhou. NeurIPS 2022."
  },
  {
    "objectID": "hw3.html#acknowledgments",
    "href": "hw3.html#acknowledgments",
    "title": "Homework 3: Large language model (LLM) prompting",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis assignment is based on a homework assignment designed by Mark Yatskar and provided by Lorraine Li."
  },
  {
    "objectID": "hw1.html",
    "href": "hw1.html",
    "title": "Homework 1: Text and string processing in Python",
    "section": "",
    "text": "Due 2025-01-23, 11:59pm. Instructions last updated 2025-01-23.\nWelcome to CS 1671/2071! In this first assignment, you’ll learn and practice some coding skills that will help you deal with text data for NLP. You will be reading/writing files, using regular expressions, and processing strings in Python. Please make sure to use Python 3 in your code. You may use any Python packages you like."
  },
  {
    "objectID": "hw1.html#learning-objectives",
    "href": "hw1.html#learning-objectives",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Learning objectives",
    "text": "Learning objectives\nAfter completing this assignments, you will be able to:\n\nLoad in text files into different data structures in Python\nUse regular expressions in Python to find and manipulate strings\nWrite Python code to produce basic statistics about a dataset of text\nSpecify the Python software environment you used to run a script"
  },
  {
    "objectID": "hw1.html#resources-to-download",
    "href": "hw1.html#resources-to-download",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Resources to download",
    "text": "Resources to download\n\nSkeleton code\nPlease download and add all your answers to the following Python script template file. It is a “skeleton” script where only the formatting is provided and you fill in the code for the rest of the file.\n\nhw1_skeleton.py\n\nPlease use a version of Python 3 to run your filled-out script. You do not have to run things on the CRCD JupyterHub unless you want to. You can just fill out and test your script locally on your own computer.\nWe encourage you to use a Python virtual environment to code this and future course assignments. Virtual environments are a way to isolate your code and its dependencies from the rest of the python programs and packages installed on your system. This is very helpful for ‘good science’ as we avoid any issues sharing our work with others and having packages break, and having a saved state where we know code works. This is a feature baked into Python with the venv module. Third-party tools are another way to create and manage virtual environments. Anaconda is a free one that I recommend.\nOne of the deliverables for this assignment is to specify the packages and package versions in the Python environment you used while running your code. This is most straightforward within a virtual environment, though you can provide all the Python packages installed on your system as an alternative.\n\n\nData\nFor Part 1, you will need the following text file:\n\nspanish_test.txt\n\nFor Part 3, you will need a small dataset of wine reviews. You can download it and unpack it in a terminal as follows:\n$ wget http://computational-linguistics-class.org/homework/python-and-bash/data.tgz\n$ tar -xzvf data.tgz \n$ ls data\nstopwords.txt    wine.txt"
  },
  {
    "objectID": "hw1.html#part-1-file-inputoutput-io",
    "href": "hw1.html#part-1-file-inputoutput-io",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Part 1: File input/output (I/O)",
    "text": "Part 1: File input/output (I/O)\nGiven a file, it is important to know how to open, read, and write using Python functions: open(), read(), and write(). The read() function returns the entire contents of the file as a string. It is often useful to read each line of a file into a list. You can do this with the readlines() function, which will split on the newline character and return the lines as a list, presevering the newline character. You can also use the splitlines() function, which will remove the newline characters.\nTake some time to also read through the encoding argument for open() as that can be a source of trouble for files that aren’t being read in properly.\nHere’s some example code for reading and writing files in Python:\n# read files\nwith open('test.txt') as f:\n    contents = f.read().splitlines()\nfor s in contents:\n    print(s)\n\n# write files\nwith open('test.txt', 'w')\n    for s in ['line1', 'line2', 'line3', 'line4'] :\n        file.write(s+'\\n')\nOften we would like to associate metadata (such as a label) with lines or chunks of text in NLP. One way of doing this is by formatting the data as a table or spreadsheet (a CSV, comma-separated value, file) with the text in a column and other columns of metadata about that text.\nFill in the text_to_csv function in hw1_skeleton.py. You can use the csv module or the more powerful pandas package, particularly the read_csv and to_csv methods to handle data in CSV format. In this function, please fill out code to read in the spanish_test.txt file and produce a CSV file with the following columns:\n\nline_id: an integer ID column for each line, starting from 1 and continuing.\ntext: the text of the line, without any newline character included\ncharacter_length: the number of characters (length) of the line, including whitespace (but not the newline characters you removed from the text column). See the Python string module or pandas string functions.\n\nSave this CSV file as spanish_test.csv. It will be part of your final submission."
  },
  {
    "objectID": "hw1.html#part-2-regular-expressions",
    "href": "hw1.html#part-2-regular-expressions",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Part 2: Regular expressions",
    "text": "Part 2: Regular expressions\nRegular expressions are a powerful way to process text by describing text patterns. Here are useful resources you may need:\n\nA fancy website to test your regex.\nPython re package that provides many regular expression functions for use.\nChapter 2 of the textbook\n\n# match patterns in given string\nimport re\npattern = 'pitt'\ntest_string = 'pittsburgh'\nresult = re.match(pattern, test_string)\nif result:\n    print(\"Search successful.\")\nelse:\n    print(\"Search unsuccessful.\") \nIn this part, you need to fill in the functions check_for_foo_or_bar and replace_rgb in the skeleton script.\n2.1. Check whether the input string meets the following condition. Useful documentation: Python match objects\n\nThe string must have both the word foo and the word bar in it, whitespace- or punctuation-delimited from other words. (not, e.g., words like foobar or bart that merely contain the word bar). You only need to match lowercase foo and bar, though it is okay if you also match any capitalized letters within foo or bar (either is acceptable).\nReturn True if the condition is met, false otherwise.\n\n2.2. Replace all RGB or hex colors with the word COLOR. Useful documentation: Python regular expression substitutions. It is fine to run multiple regular expressions substitutions if you like.\n\nPossible example formats for a color string: #0f0, #0b013a, #37EfaA, rgb(1, 1, 1), rgb(255, 19, 32), rgb(00, 001, 18.0), or rgb(0.1, 0.5, 1.0).\nNote that there is no need to try other formats that are not listed above. There is also no need to validate the ranges of the rgb values.\nHowever, you should make sure all numbers are indeed valid numbers. For example, #xyzxyz should return false as these are not valid hex digits. Similarly, rgb(c00l, 255, 255) should return false.\nOnly replace matching colors which are at the beginning or end of the line, or are space separated from the text around them. For example, due to the trailing period: I like rgb(1, 2, 3) and rgb(2, 3, 4). becomes I like COLOR and rgb(2, 3, 4).\nReturn the full text with all RGB or hex colors replaced with the word COLOR."
  },
  {
    "objectID": "hw1.html#part-3-text-processing-in-python",
    "href": "hw1.html#part-3-text-processing-in-python",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Part 3: Text Processing in Python",
    "text": "Part 3: Text Processing in Python\nFor this part, you will be playing with a small data set of wine reviews (see the Data section above for download instructions).\nwine.txt is in the format of one review per line, followed but a star rating between 1 and 5 (except for 3 reviews, where the review decided to go rogue and give 6 stars. Pft.) The text of the review and the star rating are separated by a single tab character. There is also a file called stopwords.txt, which you will use for question 3.6.\nwine.txt is also a little peculiar in its format. The encoding of the text file is Latin1 / ISO-8859-1 and depending on the OS of your machine, the default encoding used when running open() may be this encoding or it could be utf-8 (the default encoding on Linux for example). To ensure compatibility specify the encoding when you read in text files.\nIn the wine_text_processing function in hw1_skeleton.py, write code that answers each of the following questions and prints the answer to standard output, followed by a newline. If you get this output it’s very likely your code works correctly! For questions where there are ties, please break the tie alphabetically (e.g. apple would come before banana). We highly recommend looking into the functions available in the Python string module.\nYou will need to write your code in the wine_text_processing function in the hw1_skeleton.py file to answer the following questions. Please note that you need to print out the answers to each of the following questions, like below:\nQuestion 3.1 outputs: `your answer`.\n \nQuestion 3.2 outputs: `your answer`.\n \nQuestion 3.3 outputs: `your answer`.\n...\nYou can choose how you split the text into words (tokenize) or otherwise identify the words in the following questions. It is recommended to use a tokenization tool. Any packages may be imported to aid this.\n3.1. What is the distribution of star ratings? Specifically, this is the counts of reviews per each star value (1 star, 2 star, etc).\n3.2. What are the 10 most common words used across all of the reviews, and how many times is each used? Don’t include stars in the review, but it is okay to include other punctuation or not (your choice).\n3.3. How many times does the word a appear?\n3.4. How many times does the word fruit appear?\n3.5. How many times does the word mineral appear?\n3.6. Common words (like a) are not as interesting as uncommon words (like mineral). In natural language processing, we call these common words stop words and often remove them before we process text. stopwords.txt gives you a list of some very common words. Remove these stopwords from your reviews. Also, try converting all the words to lowercase (since we probably don’t want to count fruit and Fruit as two different words). Now what are the 10 most common words across all of the reviews, and how many times is each used?\n3.7. You should continue to use the preprocessed reviews for the following questions (lowercased, no stopwords). What are the 10 most used words among the 5-star reviews, and how many times is each used?\n3.8. What are the 10 most used words among the 1-star reviews, and how many times is each used?\n3.9. Gather two sets of reviews: 1) Those that use the word red and 2) those that use the word white. What are the 10 most frequent words in the red reviews which do not appear in the white reviews?\n3.10. What are the 10 most frequent words in the white reviews which do not appear in the red reviews?"
  },
  {
    "objectID": "hw1.html#deliverables",
    "href": "hw1.html#deliverables",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Deliverables",
    "text": "Deliverables\n\nYour output CSV from Part 1, named spanish_test.csv\nA modified hw1_skeleton.py file that contains your solutions. There is no need to put in a main function to run other functions. We will directly run the functions you filled in for grading.\nA README.txt file explaining\n\nhow to run your code\nwhat version of Python you used\nany additional resources, references, or web pages you’ve consulted\nany person with whom you’ve discussed the assignment and describe the nature of your discussions\nany generative AI tool used, and how it was used\nany unresolved issues or problems\n\nA requirements.txt file listing all Python packages and their versions in your environment (or on your system if you did not use a virtual environment). This may be created using pip freeze &gt; requirements.txt, conda list -e &gt; requirements.txt if using Anaconda, or through the pipenv package.\n\nPlease submit this material on Canvas as individual files. Only files with .py or .txt file extensions will be accepted. If you used Jupyter Notebook to complete the assignment, please download it as a .py script."
  },
  {
    "objectID": "hw1.html#grading",
    "href": "hw1.html#grading",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Grading",
    "text": "Grading\nWe will be running your code on a different input file to test its performance.  This assignment is worth 90 points."
  },
  {
    "objectID": "hw1.html#acknowledgments",
    "href": "hw1.html#acknowledgments",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis assignment is adapted from Prof. Mark Yatskar and Prof. Lorraine Li."
  },
  {
    "objectID": "hw0.html",
    "href": "hw0.html",
    "title": "Homework 0: CRCD JupyterHub setup",
    "section": "",
    "text": "Due 2025-01-22, 11:59pm. Instructions last updated 2025-01-21.\nThis assignment is worth 5 points of extra credit. It is not required.\nThis assignment is simply for you to get set up with installing Python packages successfully on the CRCD JupyterHub, which we will use for in-class coding activities and likely some homework assignments and project work in this class."
  },
  {
    "objectID": "hw0.html#instructions",
    "href": "hw0.html#instructions",
    "title": "Homework 0: CRCD JupyterHub setup",
    "section": "Instructions",
    "text": "Instructions\n\nMake sure you can log in to the CRCD JupyterHub at jupyter.crc.pitt.edu with your Pitt credentials. You can select the default Teach - 6 cores, 3 hours as your job profile. If you are off-campus or not on WIRELESS-PITTNET, you will need to log in to the Pitt VPN through the GlobalProtect app. Instructions for setting that up are here.\nRemove past versions of session2_text_normalization.ipynb. In the cs1671_jupyterhub folder (if you have one), delete session2_text_normalization.ipynb.\nClick the following nbgitpuller link. This should load the newest version of session2_text_normalization.ipynb, which should look like this if you’re curious.\nDouble-click session2_text_normalization.ipynb on the left-hand side panel to open the Jupyter notebook. It should not matter what kernel is selected. The default Python 3 (ipykernel) is fine.\nRun the first set of cells under the Setup section. That is all you have to do. You do not have to run the rest of the notebook.\nTake a screenshot of the output of those first cells, including import nltk, and submit it on Canvas. Ideally you are able to import nltk, but even if there are errors, that’s okay! You will still get extra credit, and I will message you on Canvas to try to figure any issues out."
  },
  {
    "objectID": "hw2.html",
    "href": "hw2.html",
    "title": "Homework 2: Text classification",
    "section": "",
    "text": "Due 2025-02-20, 11:59pm. Instructions last updated 2025-02-12."
  },
  {
    "objectID": "hw2.html#learning-objectives",
    "href": "hw2.html#learning-objectives",
    "title": "Homework 2: Text classification",
    "section": "Learning objectives",
    "text": "Learning objectives\nAfter completing this assignment, students will be able to:\n\nImplement a text classification system using logistic regression and feature-based approaches\nDesign and implement a cross-validation evaluation for a text classification system\nIdentify informative features in a feature-based text classification system\nAnalyze errors in an NLP system"
  },
  {
    "objectID": "hw2.html#implement-a-deception-classifier",
    "href": "hw2.html#implement-a-deception-classifier",
    "title": "Homework 2: Text classification",
    "section": "Implement a deception classifier",
    "text": "Implement a deception classifier\nYou will design and implement a program to classify if a comment from a player of the Diplomacy game is truthful or not.\nYour script should be able to take the filename of a dataset as a single keyword argument. You can use any packages you want for this (scikit-learn, spaCy, NLTK, Gensim, etc., as well as any code from Homework 1 or any in-class example notebook). Any packages used, along with version numbers, should be specified in a requirements.txt file. The version of Python used should also be specified in your README.txt file. If you will be using a language other than Python, please let us know before submitting."
  },
  {
    "objectID": "hw2.html#dataset",
    "href": "hw2.html#dataset",
    "title": "Homework 2: Text classification",
    "section": "Dataset",
    "text": "Dataset\nHere is the dataset that you should download for this assignment:\n\ndiplomacy_cv.csv. This dataset has a variety of fields, but the most important are:\n\ntext: the text of the comment\nintent: 0 for truth, 1 for lie\n\ndiplomacy_kaggle.csv (only necessary if participating in the optional challenge). This data has the same fields as the training data, but does not have the “correct” intent filled in. This file is to be used as a test set for the optional challenge competition hosted on Kaggle.\n\nThis dataset is from a recording of online players of Diplomacy, as presented in Peskov et al. 2020. Negotiation and back-stabbing are key elements of the Diplomacy game."
  },
  {
    "objectID": "hw2.html#part-1-feature-based-logistic-regression-models",
    "href": "hw2.html#part-1-feature-based-logistic-regression-models",
    "title": "Homework 2: Text classification",
    "section": "Part 1: Feature-based logistic regression models",
    "text": "Part 1: Feature-based logistic regression models\nIn this section, you will build a logistic regression model based on bag-of-word features and/or features of your own design. You can do whatever preprocessing you see fit. You will report performance using 5-fold cross-validation on the diplomacy_cv.csv dataset, which you will set up. Make sure to just extract features (bag-of-words, etc) from the training set and not the test folds within cross-validation. See the scikit-learn documentation on cross-validation for different scikit-learn functions for cross-validation.\nImplement and try the following feature and model combinations:\n\nLogistic regression with bag-of-words (unigram) features. Build a logistic regression classifier that uses bag-of-words (unigram) features.\nLogistic regression with your own features/change in preprocessing. Design and test at least two modifications (custom features or preprocessing changes) to unweighted unigram features. Note that these features can be used in conjunction with bag-of-words features or by themselves. Possible features/changes to add and test include:\n\nTf-idf transformed bag-of-words features\nHigher order n-gram features (bigrams, trigrams, or combinations of them) beyond the unigrams used for the bag-of-words features\nDifferent preprocessing (stemming, different tokenizations, stopword removal)\nChanging count bag-of-words features to binary 0 or 1 for the presence of unigrams\nIncorporating features from columns in the dataset other than text\nReducing noisy features with feature selection\nCounts or added weight from custom word lists\nAny other custom-designed feature (such as length of input, number of capitalized words, etc)\n\n\nYou will thus have 3 total logistic regression models: one using bag-of-word features and 2 with your own selected features or preprocessing changes.\nIn the report, please provide:\n\nA table of 5-fold cross-validation performance scores for models trained on each set of features. Include accuracy as well as precision, recall, and f1-score for the positive (lying) class. Please average these scores across the 5 folds for each evaluation metric (there is no need to include scores for each fold).\nFor each feature or change in input text processing:\n\nDescribe your motivation for including the feature\nDiscussion of results: Did it improve performance or not? (Either result is fine. It is not necessary to beat logistic regression with unigram features.)\n\nFor a feature-based model of your choice:\n\nExtract and discuss the most informative features that are mostly strongly positively and negatively associated with deception. Report the 5 features with the highest weights and 5 features with the lowest (negative) weights. Discuss how these may or may not make sense for this task. You may adapt code provided by the instructor, use another source online, or write your own. Give specific informative features, such as particular words (e.g. “actually”) for bag-of-words features, instead of sets of features like “tf-idf unigram features”.\nDo an error analysis. From one of the cross-validation runs, provide a confusion matrix on the test fold, not on training folds. You can also choose to create a separate development (test) set with another train-test split from the data, train another classifier, and provide a confusion matrix from that. Sample examples from both false negatives and false positives and present a few of them in the report. Do you see any patterns in these errors? How might these errors be addressed with different features or if the system could understand something else? (You don’t have to implement these, just speculate.)"
  },
  {
    "objectID": "hw2.html#part-2-optional-submit-your-classifier-in-the-class-challenge",
    "href": "hw2.html#part-2-optional-submit-your-classifier-in-the-class-challenge",
    "title": "Homework 2: Text classification",
    "section": "Part 2 (Optional) Submit your classifier in the class challenge",
    "text": "Part 2 (Optional) Submit your classifier in the class challenge\nOptionally, you can submit your classifier to run on a hidden held-out test set as part of a class competition. Bonus points will be awarded in the competition as follows, as measured by accuracy on our held-out test set.\n\n6 bonus points for the best-performing logistic regression classifier\n4 bonus points for the 2nd best-performing logistic regression classifier\n2 bonus points for submitting any system (and not getting 1st or 2nd place)\n\n\nHow to submit your classifier\nThis optional competition is conducted on Kaggle. See this page for instructions on how to submit: https://www.kaggle.com/t/86f51f2238334c41b13bdb6c4f1b6fa6\nYou will need to create a Kaggle account to submit. Please provide your Kaggle username used in the competition in your report so we can assign any bonus points. Note that this username will be visible in a leaderboard to other challenge competition participants."
  },
  {
    "objectID": "hw2.html#notes",
    "href": "hw2.html#notes",
    "title": "Homework 2: Text classification",
    "section": "Notes",
    "text": "Notes\n\nDon’t feel like you need to write things from scratch; use as many packages as you want. Class Jupyter notebooks, Google, Stack Overflow, and NLP/ML software documentation are your friend! Adapting and consulting other approaches is fine and should be noted in comments in the code and/or in the README.txt. Just don’t use complete, fully-formed implementations, including from generative AI tools. Use all resources as aids, not as a final product.\nOptionally, you may incorporate any form of regularization that you like."
  },
  {
    "objectID": "hw2.html#deliverables",
    "href": "hw2.html#deliverables",
    "title": "Homework 2: Text classification",
    "section": "Deliverables",
    "text": "Deliverables\n\nYour report with results and answers to questions in Part 1, named hw2_{your pitt email id}.pdf. No need to include @pitt.edu, just use the email ID before that part. For example: report_mmyoder_hw2.pdf.\n\nIf participating in the challenge, the Kaggle username you used to submit your predictions\nIf participating in the challenge, your code used for that in a file named hw2_{your pitt email id}_kaggle.py.\n\nYour code used to train models and estimate performance with cross-validation in a file named hw2_{your pitt email id}_cv.py.\nA README.txt file explaining\n\nhow to run the code you used to train your models and estimate cross-validation performance\nthe version of Python used\nany additional files needed to run the code\nany additional resources, references, or web pages you’ve consulted\nany person with whom you’ve discussed the assignment and describe the nature of your discussions\nany generative AI tool used, and how it was used\nany unresolved issues or problems\n\nA requirements.txt file with:\n\nall Python packages and package versions in the computing environment you used in case we replicate your experiments\n\n\nPlease submit all of this material on Canvas. We will grade your report and look over your code."
  },
  {
    "objectID": "hw2.html#acknowledgments",
    "href": "hw2.html#acknowledgments",
    "title": "Homework 2: Text classification",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis assignment is inspired from a homework assignment by Prof. Diane Litman. Data is from Peskov et al. 2020."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "",
    "text": "School of Computing and Information, University of Pittsburgh\nSpring 2025"
  },
  {
    "objectID": "index.html#participation-grade",
    "href": "index.html#participation-grade",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Participation grade",
    "text": "Participation grade\nIn-class, collaborative activities are better learning experiences when students come to class and participate. To encourage participation, there is a participation grade worth 10% of the total course grade. The majority of that grade comes from attendance, which will be taken via Top Hat on randomly selected class sessions. The rest of the grade will be assigned based on whether a student asked questions in class or otherwise (such as during office hours), or partipated in in-class activites. If you did any of this basic engagement, full credit will be awarded."
  },
  {
    "objectID": "index.html#grading-scale",
    "href": "index.html#grading-scale",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Grading scale",
    "text": "Grading scale\n\n\n\nRange\nLetter grade\n\n\n\n\n92.5 – 100%\nA\n\n\n90.0 – &lt;92.5%\nA-\n\n\n87.5 – &lt;90.0%\nB+\n\n\n82.5 – &lt;87.5%\nB\n\n\n80.0 – &lt;82.5%\nB-\n\n\n77.5 – &lt;80.0%\nC+\n\n\n72.5 – &lt;77.5%\nC\n\n\n70.0 – &lt;72.5%\nC-\n\n\n67.5 – &lt;70.0%\nD+\n\n\n62.5 – &lt;67.5%\nD\n\n\n60.0 – &lt;62.5%\nD-\n\n\n&lt; 60%\nF\n\n\n\nFeel free to contact the instructor or schedule an office hours appointment to talk about any issues you might have with your grade."
  },
  {
    "objectID": "index.html#late-work-policy",
    "href": "index.html#late-work-policy",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Late work policy",
    "text": "Late work policy\nStudents are granted 5 total late days across all homework assignments and quizzes without penalty. After those five late days, you will be penalized 10% for each day that your submission is late except in extreme unforeseen circumstances. Group project work will be penalized 10% for each day late. No late work will be accepted for the project report."
  },
  {
    "objectID": "index.html#assignment-resubmission-policy",
    "href": "index.html#assignment-resubmission-policy",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Assignment resubmission policy",
    "text": "Assignment resubmission policy\nIf you are unsatisfied with your grade on an assignment and wish to resubmit work, talk with the instructor. Resubmissions are handled case by case, but are generally accepted in cases where parts of the assignment are missing (sections of the rubric are 0). Updated or added text in resubmitted reports must be highlighted in yellow. Resubmissions are subject to an automatic 10% deduction. Only 1 resubmission per homework assignment will be accepted."
  },
  {
    "objectID": "index.html#academic-integrity-policy",
    "href": "index.html#academic-integrity-policy",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Academic integrity policy",
    "text": "Academic integrity policy\nStudents in this course will be expected to comply with the University of Pittsburgh’s Policy on Academic Integrity. Any student suspected of violating this obligation for any reason during the semester will be required to participate in the procedural process, initiated at the instructor level, as outlined in the University Guidelines on Academic Integrity. To learn more about Academic Integrity, visit the Academic Integrity Guide for an overview of the topic. For hands-on practice, complete the Academic Integrity Modules.\n\nGenerative AI policy\nYou are allowed to use generative AI programs (ChatGPT, etc.) as a student in this course in limited circumstances. Since much of this course is about developing such tools in NLP, using currently available tools can expose you to the current capabilities and limitations of such systems.\nHowever, your ethical responsibilities as a student remain the same. You must follow the University of Pittsburgh’s Policy on Academic Integrity. Here are some principles to keep in mind that can help you determine whether or not a specific use of generative AI is acceptable in this course (for all forms of generation: writing, code, images or other forms). Please ask the instructor if you are not sure about a specific use. You will not be blamed or retaliated against for asking.\n\nUse as an aid, not for a finished product. LLMs could be used in this course to generate ideas, draft bibliographies, study guides, or for revising their existing writing. Use for drafting entire homework or project reports is not acceptable, even if students revise this draft, since being able to communicate NLP procedures and research is a learning objective. Also keep in mind that language models have no notion of reality and will hallucinate facts and citations.\nCite its use. The University of Pittsburgh’s academic integrity policy applies to all uncited or improperly cited use of content, whether that work is created by human beings alone or in collaboration with a generative AI. If you use a generative AI tool to develop content for an assignment, you are required to cite the tool’s contribution to your work. In practice, cutting and pasting content from any source without citation is plagiarism. Likewise, paraphrasing content from a generative AI without citation is plagiarism. Similarly, using any generative AI tool without appropriate acknowledgement will be treated as plagiarism. See the APA guidelines on how to cite ChatGPT. Publicly available LLMs are relatively new, and so best practices in education are still being worked out. Citing your use of LLMs will also inform the instructor on how such tools are being used in education for developing better future policies.\nYou are responsible for the work you turn in. As we will discuss in this course, LLMs and other generative AI systems can and do generate biased, socially problematic language and assert unfounded claims. Ultimately the text you submit will be treated as reflecting your own work, and you are responsible for it.\n\nAdapted from faculty in the Carnegie Mellon University Heinz College of Information Systems and Public Policy, with guidance from the Carnegie Mellon University Eberly Center for Teaching Excellence."
  },
  {
    "objectID": "index.html#disability-rights",
    "href": "index.html#disability-rights",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Disability rights",
    "text": "Disability rights\nThe teaching staff of this course view disabilities as deficits not in disabled people but in the institutions and societies that are structured to disadvantage disabled people. If you have a disability (visible or invisible), please let us know as soon as possible. You don’t need to tell us the nature of the disability. You are encouraged to work with Disability Resources and Services (DRS), 140 William Pitt Union, (412) 648-7890, drsrecep@pitt.edu, (412) 228-5347 for P3 ASL users, as early as possible in the term. DRS will work with you to determine reasonable accommodations for this course. This might include lecture materials that are usable by people with visual disabilities, sign language interpretation, captioning, flexible due dates, etc.\nAdapted from policies by David Mortensen and Lori Levin at Carnegie Mellon University."
  },
  {
    "objectID": "index.html#religious-observances",
    "href": "index.html#religious-observances",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Religious Observances",
    "text": "Religious Observances\nThe observance of religious holidays (activities observed by a religious group of which a student is a member) and cultural practices are an important reflection of diversity. As your instructor, I am committed to providing equivalent educational opportunities to students of all belief systems. At the beginning of the semester, you should review the course requirements to identify foreseeable conflicts with assignments, exams, or other required attendance. Please contact me as early as possible to allow time for us to discuss and make fair and reasonable adjustments to the schedule and/or tasks."
  },
  {
    "objectID": "index.html#statement-on-scholarly-discourse",
    "href": "index.html#statement-on-scholarly-discourse",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Statement on scholarly discourse",
    "text": "Statement on scholarly discourse\nIn this course we will be discussing some complex issues on which all of us have strong feelings and, in many cases, unfounded attitudes. It is essential that we approach this endeavor with our minds open to evidence that may conflict with our presuppositions. Moreover, it is vital that we treat each other’s opinions and comments with courtesy even when they diverge and conflict with our own. We must avoid personal attacks and the use of ad hominem arguments to invalidate each other’s positions. Instead, we must develop a culture of civil argumentation, wherein all positions have the right to be defended and argued against in intellectually reasoned ways. It is this standard that everyone must accept in order to stay in this class; a standard that applies to all inquiry in the university, but whose observance is especially important in a course whose subject matter is so emotionally charged.\nAdapted from a California State University course: Race, Racism and Critical Thinking."
  },
  {
    "objectID": "index.html#student-wellness",
    "href": "index.html#student-wellness",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Student wellness",
    "text": "Student wellness\nCollege can be an exciting and challenging time for students. Taking time to maintain your well-being and seek appropriate support can help you achieve your goals and lead a fulfilling life. It can be helpful to remember that we all benefit from assistance and guidance at times, and there are many resources available to support your well-being while you are at Pitt. You are encouraged to visit Thrive@Pitt to learn more about well-being and the many campus resources available to help you thrive.\nIf you or anyone you know experiences overwhelming academic stress, persistent difficult feelings and/or challenging life events, you are strongly encouraged to seek support. In addition to reaching out to friends and loved ones, consider connecting with a faculty member you trust for assistance connecting to helpful resources.\nThe University Counseling Center is also here for you. You can call 412-648-7930 at any time to connect with a clinician. If you or someone you know is feeling suicidal, please call the University Counseling Center at any time at 412-648-7930. You can also contact Resolve Crisis Network at 888-796-8226."
  },
  {
    "objectID": "index.html#equity-and-inclusion",
    "href": "index.html#equity-and-inclusion",
    "title": "CS 1671/2071 Human Language Technologies",
    "section": "Equity and inclusion",
    "text": "Equity and inclusion\nThe University of Pittsburgh does not tolerate any form of discrimination, harassment, or retaliation based on disability, race, color, religion, national origin, ancestry, genetic information, marital status, familial status, sex, age, sexual orientation, veteran status or gender identity or other factors as stated in the University’s Title IX policy. The University is committed to taking prompt action to end a hostile environment that interferes with the University’s mission. For more information about policies, procedures, and practices, visit the Civil Rights & Title IX Compliance web page.\nI ask that everyone in the class strive to help ensure that other members of this class can learn in a supportive and respectful environment. If there are instances of the aforementioned issues, please contact the Title IX Coordinator, by calling 412-648-7860, or emailing titleixcoordinator@pitt.edu. Reports can also be filed online. You may also choose to report this to a faculty/staff member; they are required to communicate this to the University’s Office of Diversity and Inclusion. If you wish to maintain complete confidentiality, you may also contact the University Counseling Center (412-648-7930)."
  }
]